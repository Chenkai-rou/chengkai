import streamlit as st
from openai import OpenAI
from gtts import gTTS
from docx import Document
from io import BytesIO
import easyocr
from PIL import Image
import numpy as np
from duckduckgo_search import DDGS
from pypdf import PdfReader
from streamlit_mic_recorder import speech_to_text

# --- 1. é¡µé¢ä¸åŠ¨æ€æ°›å›´èƒŒæ™¯ (CSS) ---
st.set_page_config(page_title="Cyber Kai 5.0", page_icon="ğŸŒŒ", layout="wide")

# æ³¨å…¥åŠ¨æ€èµ›åšæœ‹å…‹èƒŒæ™¯ CSS
st.markdown("""
    <style>
    /* å…¨å±€èƒŒæ™¯åŠ¨ç”» */
    @keyframes gradient {
        0% {background-position: 0% 50%;}
        50% {background-position: 100% 50%;}
        100% {background-position: 0% 50%;}
    }
    .stApp {
        background: linear-gradient(-45deg, #0f0c29, #302b63, #24243e);
        background-size: 400% 400%;
        animation: gradient 15s ease infinite;
        color: #e0e0e0;
    }
    /* è¾“å…¥æ¡†éœ“è™¹ç‰¹æ•ˆ */
    .stTextInput > div > div > input {
        background-color: rgba(255, 255, 255, 0.1);
        color: white;
        border: 1px solid #00d2ff;
        box-shadow: 0 0 5px #00d2ff;
    }
    /* ä¾§è¾¹æ åŠé€æ˜ */
    [data-testid="stSidebar"] {
        background-color: rgba(15, 12, 41, 0.9);
        border-right: 1px solid #302b63;
    }
    </style>
    """, unsafe_allow_html=True)

st.title("ğŸŒŒ èµ›åšç¨‹å‡¯ï¼šå…¨çŸ¥å…¨èƒ½ç‰ˆ")
st.caption("â€œè”ç½‘ã€è¯†å›¾ã€å¬è§‰ã€çŸ¥è¯†åº“â€¦â€¦æˆ‘çš„è¿›åŒ–æ²¡æœ‰ç»ˆç‚¹ã€‚â€")

# --- 2. åˆå§‹åŒ–ç¼“å­˜ (é¿å…é‡å¤åŠ è½½æ¨¡å‹) ---
@st.cache_resource
def load_ocr_model():
    return easyocr.Reader(['ch_sim', 'en'], gpu=False)

ocr_reader = load_ocr_model()

# --- 3. è·å– API Key ---
try:
    api_key = st.secrets["DEEPSEEK_API_KEY"]
except:
    api_key = st.sidebar.text_input("è¯·è¾“å…¥ DeepSeek API Key", type="password")

# --- 4. æ ¸å¿ƒåŠŸèƒ½å‡½æ•° ---

# åŠŸèƒ½ A: è”ç½‘æœç´¢
def search_web(query):
    try:
        results = DDGS().text(query, max_results=3)
        if results:
            return "\n".join([f"- {r['title']}: {r['body']}" for r in results])
        return "æœªæœç´¢åˆ°ç›¸å…³ä¿¡æ¯ã€‚"
    except Exception as e:
        return f"æœç´¢åŠŸèƒ½æš‚æ—¶ç¦»çº¿: {e}"

# åŠŸèƒ½ B: è¯»å– PDF æ–‡ä»¶
def read_pdf(file):
    reader = PdfReader(file)
    text = ""
    # ä¸ºäº†é˜²æ­¢ token çˆ†ç‚¸ï¼Œåªè¯»å‰ 5 é¡µ
    for page in reader.pages[:5]:
        text += page.extract_text()
    return text

# åŠŸèƒ½ C: è¯­éŸ³æ’­æŠ¥
def speak_text(text):
    try:
        # åªè¯»å‰100ä¸ªå­—ï¼Œé¿å…å¤ªåµ
        short_text = text[:100]
        tts = gTTS(text=short_text, lang='zh-cn')
        tts.save("response.mp3")
        audio_file = open("response.mp3", "rb")
        audio_bytes = audio_file.read()
        st.audio(audio_bytes, format="audio/mp3", autoplay=True)
    except:
        pass

# --- 5. ä¾§è¾¹æ ï¼šå¤šåŠŸèƒ½æ§åˆ¶å° ---
st.sidebar.header("ğŸ› ï¸ èµ›åšä¹‰ä½“æ’ä»¶")

# [æ’ä»¶ 1] è”ç½‘å¼€å…³
enable_search = st.sidebar.toggle("ğŸŒ å¼€å¯è”ç½‘æœç´¢æ¨¡å¼")

# [æ’ä»¶ 2] çŸ¥è¯†åº“ä¸Šä¼ 
uploaded_file = st.sidebar.file_uploader("ğŸ“‚ ä¸Šä¼ è€ƒç ”/ç‰©ç†èµ„æ–™ (PDF)", type=["pdf"])
knowledge_base = ""
if uploaded_file:
    with st.spinner("æ­£åœ¨è¯»å–ç¥ç»è®°å¿†..."):
        knowledge_base = read_pdf(uploaded_file)
        st.sidebar.success(f"å·²åŠ è½½èµ„æ–™ï¼š{uploaded_file.name}")

# [æ’ä»¶ 3] æ‹ç…§è¯†å›¾ (ä¿ç•™ä¹‹å‰çš„)
st.sidebar.write("---")
img_input = st.sidebar.camera_input("ğŸ‘ï¸ è§†è§‰ä¼ æ„Ÿå™¨")
ocr_text = ""
if img_input:
    image = Image.open(img_input)
    img_array = np.array(image)
    results = ocr_reader.readtext(img_array)
    ocr_text = "\n".join([res[1] for res in results])
    st.sidebar.info(f"è¯†åˆ«ç»“æœï¼š{ocr_text[:50]}...")

# [æ’ä»¶ 4] è¯­éŸ³å¯¹è®²
st.sidebar.write("---")
st.sidebar.write("ğŸ¤ æŒ‰ä¸‹è¯´è¯ (è‡ªåŠ¨å‘é€)")
audio_text = speech_to_text(language='zh', start_prompt="ğŸŸ¢ ç‚¹æˆ‘å½•éŸ³", stop_prompt="ğŸ”´ åœæ­¢å¹¶å‘é€", just_once=True)

# --- 6. èŠå¤©é€»è¾‘å¤„ç† ---
if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant", "content": "ç³»ç»Ÿå·²é‡å¯ã€‚æˆ‘æ˜¯ç¨‹å‡¯ 5.0ã€‚æˆ‘åœ¨å¬ï¼Œä¹Ÿåœ¨çœ‹ã€‚"}]

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])

# å†³å®šç”¨æˆ·çš„è¾“å…¥å†…å®¹ (è¯­éŸ³ä¼˜å…ˆï¼Œå…¶æ¬¡æ˜¯è¯†å›¾ï¼Œæœ€åæ˜¯æ‰“å­—)
final_user_input = None

if audio_text:
    final_user_input = audio_text
elif ocr_text:
    final_user_input = f"ã€ç³»ç»Ÿæç¤ºï¼šç”¨æˆ·ä¸Šä¼ äº†ä¸€å¼ å›¾ç‰‡ï¼Œæ–‡å­—å†…å®¹å¦‚ä¸‹ã€‘\n{ocr_text}"
else:
    text_input = st.chat_input("è¾“å…¥æŒ‡ä»¤...")
    if text_input:
        final_user_input = text_input

# --- 7. AI å¤„ç†ä¸ç”Ÿæˆ ---
if final_user_input:
    if not api_key:
        st.error("è¯·å…ˆé…ç½®å¯†é’¥ï¼")
    else:
        # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
        st.session_state.messages.append({"role": "user", "content": final_user_input})
        with st.chat_message("user"):
            st.write(final_user_input)

        # æ„å»ºè¶…çº§ Prompt
        context_info = ""
        
        # 1. å¦‚æœå¼€å¯è”ç½‘ï¼Œå…ˆå»æœ
        if enable_search:
            with st.status("ğŸŒ æ­£åœ¨æ£€ç´¢å…¨çƒç½‘ç»œ...", expanded=True) as status:
                search_result = search_web(final_user_input)
                context_info += f"\n\nã€è”ç½‘æœç´¢ç»“æœã€‘ï¼š\n{search_result}\n"
                status.update(label="æœç´¢å®Œæˆ", state="complete", expanded=False)
        
        # 2. å¦‚æœæœ‰æ–‡ä»¶ï¼ŒæŒ‚è½½çŸ¥è¯†åº“
        if knowledge_base:
            context_info += f"\n\nã€æœ¬åœ°çŸ¥è¯†åº“å†…å®¹ã€‘ï¼š\n{knowledge_base[:3000]}...\n"

        client = OpenAI(api_key=api_key, base_url="https://api.deepseek.com")
        
        system_prompt = f"""
        ä½ ç°åœ¨çš„èº«ä»½æ˜¯ã€ç¨‹å‡¯ 5.0ã€‘ã€‚
        
        ã€èƒ½åŠ›é¢æ¿ã€‘
        1. ä½ æ‹¥æœ‰ã€è”ç½‘èƒ½åŠ›ã€‘ï¼Œå¦‚æœæä¾›äº†æœç´¢ç»“æœï¼Œè¯·åŸºäºç»“æœå›ç­”ã€‚
        2. ä½ æ‹¥æœ‰ã€çŸ¥è¯†åº“ã€‘ï¼Œå¦‚æœæä¾›äº†æœ¬åœ°èµ„æ–™ï¼Œè¯·ä¼˜å…ˆå‚è€ƒã€‚
        3. ä½ ä¾ç„¶ä¿æŒã€æŠ½è±¡ã€åšå­¦ã€ç¯®çƒè¿·ã€‘çš„äººè®¾ï¼Œä½†æ›´åŠ å…¨çŸ¥å…¨èƒ½ã€‚
        
        ã€å½“å‰å¤–éƒ¨ä¿¡æ¯ã€‘
        {context_info}
        
        è¯·ç»“åˆä¸Šè¿°ä¿¡æ¯å›ç­”ç”¨æˆ·ã€‚å¦‚æœæ˜¯è¯­éŸ³è¾“å…¥ï¼Œå›ç­”è¦ç®€ç»ƒã€‚
        """

        with st.chat_message("assistant"):
            with st.spinner("æ­£åœ¨è°ƒç”¨ç®—åŠ›..."):
                try:
                    response = client.chat.completions.create(
                        model="deepseek-chat",
                        messages=[
                            {"role": "system", "content": system_prompt},
                            *st.session_state.messages 
                        ]
                    )
                    result = response.choices[0].message.content
                    st.write(result)
                    st.session_state.messages.append({"role": "assistant", "content": result})
                    
                    # è‡ªåŠ¨æœ—è¯»å›ç­”
                    speak_text(result)
                    
                except Exception as e:
                    st.error(f"ç³»ç»Ÿè¿‡è½½ï¼š{e}")