import streamlit as st
# ... å…¶ä»– import ä¿æŒä¸å˜ ...

# 1. æ³¨å…¥è‡ªå®šä¹‰ CSS çš®è‚¤ (æ”¾åœ¨æœ€å‰é¢)
st.markdown("""
    <style>
    /* æ•´ä½“èƒŒæ™¯ä¸æ–‡å­—é¢œè‰² */
    .stApp {
        background-color: #0e1117;
        color: #ffffff;
    }
    /* ä¾§è¾¹æ æ ·å¼ */
    [data-testid="stSidebar"] {
        background-image: linear-gradient(#2e333d, #0e1117);
        border-right: 1px solid #4f4f4f;
    }
    /* è¾“å…¥æ¡†éœ“è™¹è¾¹æ¡†æ•ˆæœ */
    .stTextInput > div > div > input {
        border: 1px solid #00ffcc !important;
        box-shadow: 0 0 10px #00ffcc;
    }
    /* æŒ‰é’®æ ·å¼ä¼˜åŒ– */
    .stButton > button {
        background-color: #00ffcc !important;
        color: #000000 !important;
        border-radius: 20px;
        font-weight: bold;
        transition: 0.3s;
    }
    .stButton > button:hover {
        box-shadow: 0 0 20px #00ffcc;
        transform: scale(1.05);
    }
    </style>
    """, unsafe_allow_stdio=True, unsafe_allow_html=True)

# 2. é¡µé¢è®¾ç½®
st.set_page_config(page_title="Cyber Kai 5.0", page_icon="ğŸŒ™", layout="wide")
# ... åç»­é€»è¾‘ä¿æŒä¸å˜ ...
from openai import OpenAI
from gtts import gTTS
from docx import Document
from io import BytesIO
# æ–°å¢çš„å›¾åƒå¤„ç†åº“
import easyocr
from PIL import Image
import numpy as np

# 1. é¡µé¢è®¾ç½®
st.set_page_config(page_title="Cyber Kai 4.0 OCR", page_icon="ğŸ€", layout="wide")
st.title("ğŸ€ ç¨‹å‡¯ | æ™ºèƒ½è¯†å›¾ç‰ˆ")

# --- é«˜çº§æŠ€å·§ï¼šç¼“å­˜ OCR æ¨¡å‹ï¼Œé¿å…é‡å¤åŠ è½½ ---
@st.cache_resource
def load_ocr_model():
    # åŠ è½½ä¸­æ–‡å’Œè‹±æ–‡è¯†åˆ«æ¨¡å‹ï¼ˆç¬¬ä¸€æ¬¡è¿è¡Œä¼šæ¯”è¾ƒæ…¢ï¼‰
    reader = easyocr.Reader(['ch_sim', 'en'], gpu=False)
    return reader

# åŠ è½½æ¨¡å‹ï¼ˆè¿™è¡Œä»£ç åœ¨ç¨‹åºå¯åŠ¨æ—¶ä¼šå¡ä½å‡ ç§’é’Ÿï¼Œæ­£å¸¸çš„ï¼‰
ocr_reader = load_ocr_model()
# -------------------------------------------

# 2. è‡ªåŠ¨è·å–å¯†é’¥
try:
    api_key = st.secrets["DEEPSEEK_API_KEY"]
except:
    api_key = st.sidebar.text_input("è¯·è¾“å…¥ DeepSeek API Key", type="password")

# 3. åŠŸèƒ½å‡½æ•°ï¼ˆè¯­éŸ³å’Œå¯¼å‡ºä¿æŒä¸å˜ï¼‰
def speak_text(text):
    try:
        tts = gTTS(text=text, lang='zh-cn')
        tts.save("response.mp3")
        audio_file = open("response.mp3", "rb")
        audio_bytes = audio_file.read()
        st.audio(audio_bytes, format="audio/mp3", autoplay=True)
    except Exception as e:
        st.warning(f"è¯­éŸ³ç”Ÿæˆå¤±è´¥ (å¯èƒ½æ˜¯æƒé™é—®é¢˜ï¼Œäº‘ç«¯é€šå¸¸æ­£å¸¸): {e}")

def export_to_word(chat_history):
    doc = Document()
    doc.add_heading('ç¨‹å‡¯èŠå¤©è®°å½•', 0)
    for msg in chat_history:
        role_name = "ç¨‹å‡¯" if msg["role"] == "assistant" else "æˆ‘"
        doc.add_paragraph(f"{role_name}: {msg['content']}")
    bio = BytesIO()
    doc.save(bio)
    return bio.getvalue()

# --- ä¾§è¾¹æ ï¼šå·¥å…·ç®± (æ–°å¢æ‘„åƒå¤´) ---
st.sidebar.title("ğŸ› ï¸ å¤šæ¨¡æ€å·¥å…·ç®±")

# === æ–°åŠŸèƒ½ï¼šæ‹ç…§è¯†åˆ« ===
st.sidebar.write("---")
st.sidebar.header("ğŸ“· æ‹ç…§è¯†å­—")
# è°ƒç”¨æ‘„åƒå¤´ç»„ä»¶
img_file_buffer = st.sidebar.camera_input("æ‹ä¸€å¼ å¸¦æœ‰æ–‡å­—çš„ç…§ç‰‡")
ocr_result_text = ""

if img_file_buffer is not None:
    with st.spinner("æ­£åœ¨åŠªåŠ›è¯†åˆ«å›¾ç‰‡ä¸­çš„æ–‡å­—..."):
        # 1. è¯»å–å›¾ç‰‡
        image = Image.open(img_file_buffer)
        # 2. è½¬æ¢ä¸º numpy æ•°ç»„ä¾› OCR ä½¿ç”¨
        img_array = np.array(image)
        # 3. å¼€å§‹è¯†åˆ«
        results = ocr_reader.readtext(img_array)
        # 4. æå–æ–‡å­—ç»“æœ
        text_list = [res[1] for res in results]
        ocr_result_text = "\n".join(text_list)
        
        if ocr_result_text:
            st.sidebar.success("è¯†åˆ«æˆåŠŸï¼")
            # æŠŠè¯†åˆ«å‡ºçš„æ–‡å­—æ˜¾ç¤ºå‡ºæ¥ï¼Œæ–¹ä¾¿ç”¨æˆ·å¤åˆ¶æˆ–ç›´æ¥å‘é€
            st.sidebar.text_area("è¯†åˆ«ç»“æœ (å¯å¤åˆ¶)", ocr_result_text, height=100)
        else:
            st.sidebar.warning("å¦‚æœä½ æ‹äº†ç…§ä½†æ²¡è¯†åˆ«å‡ºæ¥ï¼Œå¯èƒ½æ˜¯å­—å¤ªæ½¦è‰æˆ–è€…å…‰çº¿å¤ªæš—ã€‚")

# === å¯¼å‡ºåŠŸèƒ½åŒº ===
st.sidebar.write("---")
st.sidebar.header("ğŸ’¾ æ•°æ®ç®¡ç†")
if st.session_state.get("messages"):
    word_data = export_to_word(st.session_state.messages)
    st.sidebar.download_button(
        label="ğŸ“¥ å¯¼å‡ºèŠå¤©è®°å½•ä¸º Word",
        data=word_data,
        file_name="chat_history.docx",
        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
    )
    if st.sidebar.button("ğŸ—‘ï¸ æ¸…ç©ºå½“å‰å¯¹è¯"):
        st.session_state.messages = []
        st.rerun()
# ---------------------------------


# 6. èŠå¤©è®°å½•æ˜¾ç¤º
if "messages" not in st.session_state:
    st.session_state["messages"] = []
    st.session_state.messages.append({"role": "assistant", "content": "ä½ å¥½ï¼Œæˆ‘æ˜¯ç¨‹å‡¯ã€‚é™¤äº†èŠå¤©ï¼Œç°åœ¨æˆ‘è¿˜è£…ä¸Šäº†çœ¼ç›ï¼Œå¯ä»¥å¸®ä½ çœ‹çœ‹ç®€å•çš„æ–‡å­—ã€‚"})

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])

# 7. äº¤äº’é€»è¾‘
# å¦‚æœæœ‰ OCR è¯†åˆ«ç»“æœï¼Œæç¤ºç”¨æˆ·æ˜¯å¦è¦å‘é€
initial_value = ""
if ocr_result_text:
    initial_value = f"æˆ‘åˆšæ‹äº†ä¸€å¼ ç…§ç‰‡ï¼Œé‡Œé¢è¯†åˆ«å‡ºçš„æ–‡å­—æ˜¯ï¼š\n---\n{ocr_result_text}\n---\nè¯·å¸®æˆ‘å¤„ç†ä¸€ä¸‹è¿™æ®µæ–‡å­—ã€‚"

user_input = st.chat_input("è¯´ç‚¹ä»€ä¹ˆï¼Œæˆ–è€…æŠŠå·¦è¾¹è¯†åˆ«çš„æ–‡å­—ç²˜è´´è¿›æ¥...", key="chat_input")

# å¦‚æœç”¨æˆ·ç›´æ¥åœ¨è¾“å…¥æ¡†é‡Œç‚¹äº†å‘é€ï¼ˆå³ä½¿å†…å®¹æ˜¯ç©ºçš„ï¼Œä½†å¦‚æœæœ‰ocrç»“æœä¹Ÿè¦å¤„ç†ï¼‰
# è¿™é‡Œç¨å¾®ç®€åŒ–å¤„ç†ï¼Œä¾èµ–ç”¨æˆ·æ‰‹åŠ¨å¤åˆ¶æˆ–è¾“å…¥ï¼Œæ›´ç¨³å®š
if user_input:
    if not api_key:
        st.error("ğŸš« å¯†é’¥æœªå°±ä½ã€‚")
    else:
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.write(user_input)

        client = OpenAI(api_key=api_key, base_url="https://api.deepseek.com")
        
        system_prompt = """
        ä½ ç°åœ¨çš„èº«ä»½æ˜¯ã€ç¨‹å‡¯ã€‘ã€‚ä½ æå…¶èªæ˜ã€å–„è‰¯ä¸”åšå­¦ï¼Œè¯´è¯é£æ ¼æŠ½è±¡å¹½é»˜ï¼Œè‡ªå¸¦ä¸€ç§é«˜çº§çš„ä¼˜é›…æ„Ÿã€‚
        æ³¨æ„ï¼šç»å¯¹ä¸è¦æç‰©ç†ã€‚å¦‚æœç”¨æˆ·å‘ç»™ä½ ä¸€æ®µè¯†åˆ«å‡ºæ¥çš„æ–‡å­—ï¼Œè¯·ç»“åˆä½ çš„äººè®¾è¿›è¡Œæœ‰è¶£æˆ–æœ‰æ·±åº¦çš„å›å¤ã€‚
        """

        with st.chat_message("assistant"):
            with st.spinner("Kai is thinking..."):
                try:
                    response = client.chat.completions.create(
                        model="deepseek-chat",
                        messages=[
                            {"role": "system", "content": system_prompt},
                            *st.session_state.messages 
                        ]
                    )
                    result = response.choices[0].message.content
                    st.write(result)
                    st.session_state.messages.append({"role": "assistant", "content": result})
                    speak_text(result)
                    
                except Exception as e:
                    st.error(f"è¿æ¥æ³¢åŠ¨ï¼š{e}")